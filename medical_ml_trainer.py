"""
åŒ»å­¦çœ¼ç§‘ç–¾ç—…AIæ¨¡å‹è®­ç»ƒå™¨
Medical Eye Disease AI Model Trainer
"""

import os
import numpy as np
import pandas as pd
from PIL import Image
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import joblib
import json
from tqdm import tqdm
import config

class MedicalEyeTrainer:
    def __init__(self):
        self.medical_data_dir = os.path.join(config.RAW_DATA_DIR, "medical")
        self.models_dir = os.path.join("models", "medical_models")
        os.makedirs(self.models_dir, exist_ok=True)
        
        # åŒ»å­¦ç±»åˆ«
        self.medical_classes = {
            'normal': 0,
            'diabetic_retinopathy': 1,
            'hypertensive_retinopathy': 2,
            'age_macular_degeneration': 3
        }
        
        self.class_names = list(self.medical_classes.keys())
        
    def extract_medical_features(self, image_path):
        """æå–åŒ»å­¦å›¾ç‰‡ç‰¹å¾"""
        try:
            with Image.open(image_path) as img:
                if img.mode != 'RGB':
                    img = img.convert('RGB')
                
                img_array = np.array(img)
                height, width, channels = img_array.shape
                
                # åŸºç¡€ç»Ÿè®¡ç‰¹å¾
                features = []
                
                # 1. é¢œè‰²ç»Ÿè®¡ç‰¹å¾
                for channel in range(3):  # RGB
                    channel_data = img_array[:, :, channel]
                    features.extend([
                        np.mean(channel_data),      # å‡å€¼
                        np.std(channel_data),       # æ ‡å‡†å·®
                        np.median(channel_data),    # ä¸­ä½æ•°
                        np.min(channel_data),       # æœ€å°å€¼
                        np.max(channel_data),       # æœ€å¤§å€¼
                    ])
                
                # 2. é¢œè‰²æ¯”ç‡ç‰¹å¾ï¼ˆåŒ»å­¦è¯Šæ–­é‡è¦ï¼‰
                r_channel = img_array[:, :, 0].astype(float)
                g_channel = img_array[:, :, 1].astype(float)
                b_channel = img_array[:, :, 2].astype(float)
                
                # é¿å…é™¤é›¶
                g_channel_safe = np.where(g_channel == 0, 1, g_channel)
                b_channel_safe = np.where(b_channel == 0, 1, b_channel)
                
                features.extend([
                    np.mean(r_channel / g_channel_safe),    # çº¢ç»¿æ¯”
                    np.mean(r_channel / b_channel_safe),    # çº¢è“æ¯”
                    np.mean(g_channel / b_channel_safe),    # ç»¿è“æ¯”
                ])
                
                # 3. äº®åº¦å’Œå¯¹æ¯”åº¦ç‰¹å¾
                gray = np.mean(img_array, axis=2)
                features.extend([
                    np.mean(gray),                          # å¹³å‡äº®åº¦
                    np.std(gray),                           # äº®åº¦æ ‡å‡†å·®
                    np.max(gray) - np.min(gray),            # å¯¹æ¯”åº¦
                ])
                
                # 4. çº¹ç†ç‰¹å¾ï¼ˆç®€åŒ–ç‰ˆï¼‰
                # æ°´å¹³æ¢¯åº¦
                grad_x = np.abs(np.diff(gray, axis=1))
                features.append(np.mean(grad_x))
                
                # å‚ç›´æ¢¯åº¦
                grad_y = np.abs(np.diff(gray, axis=0))
                features.append(np.mean(grad_y))
                
                # 5. åŒºåŸŸç‰¹å¾ï¼ˆä¸­å¿ƒvsè¾¹ç¼˜ï¼‰
                center_h, center_w = height // 2, width // 2
                center_region = img_array[center_h-50:center_h+50, center_w-50:center_w+50]
                if center_region.size > 0:
                    features.extend([
                        np.mean(center_region[:, :, 0]),    # ä¸­å¿ƒçº¢è‰²
                        np.mean(center_region[:, :, 1]),    # ä¸­å¿ƒç»¿è‰²
                        np.mean(center_region[:, :, 2]),    # ä¸­å¿ƒè“è‰²
                    ])
                else:
                    features.extend([0, 0, 0])
                
                # 6. è¡€ç®¡ç›¸å…³ç‰¹å¾ï¼ˆçº¢è‰²æˆåˆ†åˆ†æï¼‰
                red_threshold = np.percentile(r_channel, 75)
                red_regions = r_channel > red_threshold
                features.extend([
                    np.sum(red_regions) / (width * height), # çº¢è‰²åŒºåŸŸæ¯”ä¾‹
                    np.mean(r_channel[red_regions]) if np.any(red_regions) else 0,  # çº¢è‰²åŒºåŸŸå¹³å‡å€¼
                ])
                
                # 7. ç—…å˜æ£€æµ‹ç‰¹å¾
                # æ£€æµ‹å¼‚å¸¸äº®ç‚¹ï¼ˆå¯èƒ½çš„æ¸—å‡ºç‰©ï¼‰
                bright_threshold = np.percentile(gray, 95)
                bright_spots = gray > bright_threshold
                features.append(np.sum(bright_spots) / (width * height))
                
                # æ£€æµ‹æš—ç‚¹ï¼ˆå¯èƒ½çš„å‡ºè¡€ç‚¹ï¼‰
                dark_threshold = np.percentile(gray, 5)
                dark_spots = gray < dark_threshold
                features.append(np.sum(dark_spots) / (width * height))
                
                return np.array(features)
                
        except Exception as e:
            print(f"ç‰¹å¾æå–é”™è¯¯ {image_path}: {e}")
            return np.zeros(26)  # è¿”å›é›¶ç‰¹å¾å‘é‡
    
    def load_medical_dataset(self):
        """åŠ è½½åŒ»å­¦æ•°æ®é›†"""
        print("ğŸ“Š åŠ è½½åŒ»å­¦çœ¼ç§‘ç–¾ç—…æ•°æ®é›†...")
        
        X = []
        y = []
        image_paths = []
        
        for class_name, class_label in self.medical_classes.items():
            class_dir = os.path.join(self.medical_data_dir, class_name)
            
            if not os.path.exists(class_dir):
                print(f"âš ï¸  ç±»åˆ«ç›®å½•ä¸å­˜åœ¨: {class_dir}")
                continue
            
            image_files = [f for f in os.listdir(class_dir) 
                          if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
            
            print(f"ğŸ“ {class_name}: {len(image_files)} å¼ å›¾ç‰‡")
            
            for filename in tqdm(image_files, desc=f"å¤„ç† {class_name}"):
                filepath = os.path.join(class_dir, filename)
                
                # æå–ç‰¹å¾
                features = self.extract_medical_features(filepath)
                
                if features is not None and len(features) > 0:
                    X.append(features)
                    y.append(class_label)
                    image_paths.append(filepath)
        
        X = np.array(X)
        y = np.array(y)
        
        print(f"ğŸ“Š æ•°æ®é›†åŠ è½½å®Œæˆ:")
        print(f"  æ ·æœ¬æ•°é‡: {len(X)}")
        print(f"  ç‰¹å¾ç»´åº¦: {X.shape[1] if len(X) > 0 else 0}")
        print(f"  ç±»åˆ«åˆ†å¸ƒ: {dict(zip(*np.unique(y, return_counts=True)))}")
        
        return X, y, image_paths
    
    def train_medical_models(self, X, y):
        """è®­ç»ƒåŒ»å­¦è¯Šæ–­æ¨¡å‹"""
        print("\nğŸ¤– è®­ç»ƒåŒ»å­¦çœ¼ç§‘ç–¾ç—…è¯Šæ–­æ¨¡å‹...")
        
        if len(X) == 0:
            print("âŒ æ²¡æœ‰æ•°æ®å¯è®­ç»ƒ")
            return {}
        
        # æ•°æ®é¢„å¤„ç†
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # æ ‡ç­¾ç¼–ç 
        label_encoder = LabelEncoder()
        y_encoded = label_encoder.fit_transform(y)
        
        # åˆ†å‰²æ•°æ®é›†
        X_train, X_test, y_train, y_test = train_test_split(
            X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
        )
        
        print(f"ğŸ“Š è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬")
        print(f"ğŸ“Š æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬")
        
        # å®šä¹‰æ¨¡å‹
        models = {
            'RandomForest': RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                random_state=42,
                class_weight='balanced'
            ),
            'SVM': SVC(
                kernel='rbf',
                C=1.0,
                gamma='scale',
                random_state=42,
                class_weight='balanced',
                probability=True
            ),
            'LogisticRegression': LogisticRegression(
                random_state=42,
                max_iter=1000,
                class_weight='balanced'
            )
        }
        
        results = {}
        
        for model_name, model in models.items():
            print(f"\nğŸ”¬ è®­ç»ƒ {model_name} æ¨¡å‹...")
            
            try:
                # è®­ç»ƒæ¨¡å‹
                model.fit(X_train, y_train)
                
                # é¢„æµ‹
                y_pred = model.predict(X_test)
                y_pred_proba = model.predict_proba(X_test) if hasattr(model, 'predict_proba') else None
                
                # è¯„ä¼°
                accuracy = accuracy_score(y_test, y_pred)
                
                # äº¤å‰éªŒè¯
                cv_scores = cross_val_score(model, X_scaled, y_encoded, cv=5)
                
                # åˆ†ç±»æŠ¥å‘Š
                class_report = classification_report(
                    y_test, y_pred, 
                    target_names=[self.class_names[i] for i in label_encoder.classes_],
                    output_dict=True
                )
                
                # æ··æ·†çŸ©é˜µ
                conf_matrix = confusion_matrix(y_test, y_pred)
                
                results[model_name] = {
                    'model': model,
                    'accuracy': accuracy,
                    'cv_mean': np.mean(cv_scores),
                    'cv_std': np.std(cv_scores),
                    'classification_report': class_report,
                    'confusion_matrix': conf_matrix.tolist(),
                    'predictions': y_pred.tolist(),
                    'probabilities': y_pred_proba.tolist() if y_pred_proba is not None else None
                }
                
                print(f"  âœ… {model_name}:")
                print(f"    å‡†ç¡®ç‡: {accuracy:.3f}")
                print(f"    äº¤å‰éªŒè¯: {np.mean(cv_scores):.3f} Â± {np.std(cv_scores):.3f}")
                
            except Exception as e:
                print(f"  âŒ {model_name} è®­ç»ƒå¤±è´¥: {e}")
                continue
        
        # ä¿å­˜é¢„å¤„ç†å™¨
        joblib.dump(scaler, os.path.join(self.models_dir, 'medical_scaler.joblib'))
        joblib.dump(label_encoder, os.path.join(self.models_dir, 'medical_label_encoder.joblib'))
        
        return results, X_test, y_test, scaler, label_encoder
    
    def save_medical_models(self, results):
        """ä¿å­˜åŒ»å­¦æ¨¡å‹"""
        print("\nğŸ’¾ ä¿å­˜åŒ»å­¦è¯Šæ–­æ¨¡å‹...")
        
        best_model = None
        best_accuracy = 0
        
        for model_name, result in results.items():
            if 'model' in result:
                # ä¿å­˜æ¨¡å‹
                model_path = os.path.join(self.models_dir, f'medical_{model_name.lower()}_model.joblib')
                joblib.dump(result['model'], model_path)
                
                # ä¿å­˜ç»“æœ
                result_copy = result.copy()
                del result_copy['model']  # ç§»é™¤æ¨¡å‹å¯¹è±¡
                
                result_path = os.path.join(self.models_dir, f'medical_{model_name.lower()}_results.json')
                with open(result_path, 'w') as f:
                    json.dump(result_copy, f, indent=2)
                
                print(f"  âœ… {model_name}: {model_path}")
                
                # è®°å½•æœ€ä½³æ¨¡å‹
                if result['accuracy'] > best_accuracy:
                    best_accuracy = result['accuracy']
                    best_model = model_name
        
        if best_model:
            print(f"ğŸ† æœ€ä½³æ¨¡å‹: {best_model} (å‡†ç¡®ç‡: {best_accuracy:.3f})")
        
        return best_model, best_accuracy
    
    def generate_medical_report(self, results):
        """ç”ŸæˆåŒ»å­¦è¯Šæ–­æŠ¥å‘Š"""
        print("\nğŸ“‹ ç”ŸæˆåŒ»å­¦è¯Šæ–­æ¨¡å‹æŠ¥å‘Š...")
        
        report = {
            'dataset_info': {
                'classes': self.class_names,
                'class_mapping': self.medical_classes,
                'total_samples': sum(len(os.listdir(os.path.join(self.medical_data_dir, cls))) 
                                   for cls in self.class_names if os.path.exists(os.path.join(self.medical_data_dir, cls))),
                'features_count': 26
            },
            'model_performance': {},
            'feature_importance': {
                'color_statistics': 'é¢œè‰²ç»Ÿè®¡ç‰¹å¾ (RGBå‡å€¼ã€æ ‡å‡†å·®ç­‰)',
                'color_ratios': 'é¢œè‰²æ¯”ç‡ç‰¹å¾ (çº¢ç»¿æ¯”ã€çº¢è“æ¯”ç­‰)',
                'brightness_contrast': 'äº®åº¦å¯¹æ¯”åº¦ç‰¹å¾',
                'texture_features': 'çº¹ç†ç‰¹å¾ (æ¢¯åº¦)',
                'region_features': 'åŒºåŸŸç‰¹å¾ (ä¸­å¿ƒvsè¾¹ç¼˜)',
                'vessel_features': 'è¡€ç®¡ç›¸å…³ç‰¹å¾',
                'lesion_features': 'ç—…å˜æ£€æµ‹ç‰¹å¾'
            }
        }
        
        for model_name, result in results.items():
            if 'accuracy' in result:
                report['model_performance'][model_name] = {
                    'accuracy': result['accuracy'],
                    'cv_mean': result['cv_mean'],
                    'cv_std': result['cv_std'],
                    'classification_report': result['classification_report']
                }
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = os.path.join(self.models_dir, 'medical_training_report.json')
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        
        return report
    
    def train_complete_medical_system(self):
        """è®­ç»ƒå®Œæ•´çš„åŒ»å­¦è¯Šæ–­ç³»ç»Ÿ"""
        print("ğŸ¥ åŒ»å­¦çœ¼ç§‘ç–¾ç—…AIè¯Šæ–­ç³»ç»Ÿè®­ç»ƒ")
        print("=" * 60)
        print("ğŸ¯ ç›®æ ‡: è®­ç»ƒå››ç±»çœ¼ç§‘ç–¾ç—…è¯Šæ–­æ¨¡å‹")
        print("ğŸ“‹ ç±»åˆ«: æ­£å¸¸ã€ç³–å°¿ç—…è§†ç½‘è†œç—…å˜ã€é«˜è¡€å‹è§†ç½‘è†œç—…å˜ã€è€å¹´é»„æ–‘å˜æ€§")
        
        # åŠ è½½æ•°æ®
        X, y, image_paths = self.load_medical_dataset()
        
        if len(X) == 0:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°åŒ»å­¦å›¾ç‰‡æ•°æ®")
            return None
        
        # è®­ç»ƒæ¨¡å‹
        results, X_test, y_test, scaler, label_encoder = self.train_medical_models(X, y)
        
        if not results:
            print("âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥")
            return None
        
        # ä¿å­˜æ¨¡å‹
        best_model, best_accuracy = self.save_medical_models(results)
        
        # ç”ŸæˆæŠ¥å‘Š
        report = self.generate_medical_report(results)
        
        print(f"\nğŸ‰ åŒ»å­¦è¯Šæ–­ç³»ç»Ÿè®­ç»ƒå®Œæˆ!")
        print("=" * 60)
        print(f"ğŸ“Š è®­ç»ƒç»“æœ:")
        for model_name, result in results.items():
            if 'accuracy' in result:
                print(f"  {model_name:20s}: {result['accuracy']:.3f} å‡†ç¡®ç‡")
        
        print(f"ğŸ† æœ€ä½³æ¨¡å‹: {best_model} ({best_accuracy:.3f})")
        print(f"ğŸ’¾ æ¨¡å‹ä¿å­˜ä½ç½®: {self.models_dir}")
        
        return results

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¥ åŒ»å­¦çœ¼ç§‘ç–¾ç—…AIæ¨¡å‹è®­ç»ƒå™¨")
    print("ğŸ¯ è®­ç»ƒçœ¼ç§‘ç–¾ç—…è¯Šæ–­æ¨¡å‹")
    print("=" * 60)
    
    trainer = MedicalEyeTrainer()
    results = trainer.train_complete_medical_system()
    
    if results:
        print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥:")
        print(f"  1. æµ‹è¯•æ¨¡å‹: python medical_inference.py")
        print(f"  2. æ¨é€åˆ°GitHub: git add . && git commit && git push")
    
    return results

if __name__ == "__main__":
    results = main()
